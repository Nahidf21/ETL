{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "240103c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a65590",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinit= pd.read_csv(\"dfinit.csv\")\n",
    "dfup1= pd.read_csv(\"dfup1.csv\")\n",
    "dfup2= pd.read_csv(\"dfup2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3565305",
   "metadata": {},
   "source": [
    "# work with dfup2 file "
   ]
  },
  {
   "cell_type": "raw",
   "id": "79116fbf",
   "metadata": {},
   "source": [
    "We are beginning work with the dfup2 dataset. This dataset splits the instrument into two separate rows. It contains a column named \"form_field\" which we use as our reference. We then divide the dataset into two distinct sets, though both retain the same \"recordid\". Following this, we drop the \"form_field\" column and set \"recordid\" as the index. \n",
    "Finally, we merge the split datasets and replace any null values with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1e71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfup2_1=dfup2[dfup2[\"form_field\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af19811",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfup2_2=dfup2[dfup2[\"form_field\"]==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94c1a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfup2_1_drop=dfup2_1.drop(columns=\"form_field\").set_index(\"recordid\")\n",
    "dfup2_2_drop=dfup2_2.drop(columns=\"form_field\").set_index(\"recordid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea7601a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfup2_merge= dfup2_1_drop.combine_first(dfup2_2_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a272871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfup2=dfup2_merge.fillna(int(-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa294f",
   "metadata": {},
   "source": [
    "# work with dfinit file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f20554",
   "metadata": {},
   "source": [
    "We fill the null values with -1 and set 'recordid' as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76ee560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinit=dfinit.fillna(-1).set_index(\"recordid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e6bfe4",
   "metadata": {},
   "source": [
    "# work with dfup1 file "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb60d3c",
   "metadata": {},
   "source": [
    "We fill the null values with -1 and set 'recordid' as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72fca830",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfup1=dfup1.fillna(-1).set_index(\"recordid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf40f03",
   "metadata": {},
   "source": [
    "# work with mapping_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f5b7da",
   "metadata": {},
   "source": [
    "We utilize the mapping_file to rename columns in the dfinit and dfup1 datasets. Initially, we extract rows from mapping_file for individual columns (\"dfinit\", \"dfup1\", \"dfup2\"). We then create three lists: mapping_file_dfinit, mapping_file_dfup1, and mapping_file_dfup2. Column names from the dfinit and dfup1 datasets are also extracted. We adopt the dfup2 column names from the mapping_file dataset as our standard column naming convention.\n",
    "\n",
    "Next, we employ a for loop to iterate over the column names in the dfup1_col list. Each column name is split using split(\"_\"), yielding two distinct pieces of data: the field name and the subfield number. We also determine the index number from mapping_file_dfup2 using the field name obtained from the split. With both the index number and subfield number in hand, we construct a new column name using the index_mapping_file number and the subfield number (from the second split value). Subsequently, we rename the column in the dfup1 dataset.\n",
    "\n",
    "The same procedure is applied to the dfinit dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdc05f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_file= pd.read_csv(\"mapping_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "998ca789",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfint_col=dfinit.columns\n",
    "dfup1_col=dfup1.columns\n",
    "mapping_file_dfinit=[]\n",
    "mapping_file_dfup1=[]\n",
    "mapping_file_dfup2=[]\n",
    "for _, row in mapping_file.iterrows():\n",
    "    mapping_file_dfinit.append(row[\"dfinit\"])\n",
    "    mapping_file_dfup1.append(row[\"dfup1\"])\n",
    "    mapping_file_dfup2.append(row[\"dfup2\"])\n",
    "    \n",
    "# print(mapping_file_dfinit)\n",
    "    \n",
    "for col in dfup1_col:\n",
    "    x=col.split(\"_\")\n",
    "    if x[0] in mapping_file_dfup1:\n",
    "        index_mapping_file=mapping_file_dfup1.index(x[0])\n",
    "        new_col_name=f\"{mapping_file_dfup2[index_mapping_file]}_{x[1]}\"\n",
    "        dfup1.rename(columns={col :new_col_name}, inplace=True)\n",
    "for col in dfint_col:\n",
    "    x=col.split(\"_\")\n",
    "    if x[0] in mapping_file_dfinit:\n",
    "        index_mapping_file=mapping_file_dfinit.index(x[0])\n",
    "        new_col_name=f\"{mapping_file_dfup2[index_mapping_file]}_{x[1]}\"\n",
    "        dfinit.rename(columns={col :new_col_name}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16145b5f",
   "metadata": {},
   "source": [
    "# work with field_index\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fbf904",
   "metadata": {},
   "source": [
    "The field_index dataset provides information about which columns are present in each of our three main datasets: dfinit, dfup1, and dfup2. We only consider columns that are available in all three datasets. First, we establish a logic, then drop an unnecessary row \"recordid\". This selection is subsequently applied to the dfinit, dfup1, and dfup2 datasets. \n",
    "Finally, we concatenate the three datasets to obtain our final consolidated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9179959",
   "metadata": {},
   "outputs": [],
   "source": [
    "fild_index= pd.read_csv(\"field_index.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "628d86d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fild_index = fild_index[(fild_index[\"dfinit\"]==1) & (fild_index[\"dfup1\"]==1) & (fild_index[\"dfup2\"]==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "101d1839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>dfinit</th>\n",
       "      <th>dfup1</th>\n",
       "      <th>dfup2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recordid</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mvl_0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hik_0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aom_0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aom_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>odr_4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>ueu_0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>ueu_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ueu_2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>ueu_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Code  dfinit  dfup1  dfup2\n",
       "0    recordid       1      1      1\n",
       "1       mvl_0       1      1      1\n",
       "2       hik_0       1      1      1\n",
       "3       aom_0       1      1      1\n",
       "4       aom_1       1      1      1\n",
       "..        ...     ...    ...    ...\n",
       "99      odr_4       1      1      1\n",
       "100     ueu_0       1      1      1\n",
       "101     ueu_1       1      1      1\n",
       "102     ueu_2       1      1      1\n",
       "103     ueu_3       1      1      1\n",
       "\n",
       "[104 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fild_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99c1960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fild_index= fild_index.drop(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83891d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fild_index_list=[]\n",
    "for _, row in fild_index.iterrows():\n",
    "    fild_index_list.append(row[\"Code\"].upper())\n",
    "dfinit= dfinit[fild_index_list]\n",
    "dfup1= dfup1[fild_index_list]\n",
    "dfup2=dfup2[fild_index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aba4e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data=pd.concat([dfinit,dfup1,dfup2],ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d075c5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
